{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GPy\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Logan/Google Drive/Oxford/DPhil/future_employment/data/helpers/skills\n"
     ]
    }
   ],
   "source": [
    "cd ../../../data/helpers/skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('skills_2009.csv')\n",
    "Y = pd.read_csv('automation_targets.csv')\n",
    "codes = pd.read_csv('codes_index.csv')\n",
    "y = pd.read_csv('automation_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## UNSOLVED\n",
    "# Using time series data â€“ multiple years\n",
    "\n",
    "## NOTES ABOUT GP MODELS\n",
    "# optimize hyperparameters\n",
    "# perform random restarts\n",
    "# allow for multiple kernels\n",
    "# optimize kernels\n",
    "# optimize variances\n",
    "\n",
    "## TO DO\n",
    "# percentile regression model evaluation\n",
    "\n",
    "# CREATE REGRESSION MODELS\n",
    "from GPy.models import GPRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from GPy.models import GPClassification\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_models = [('gpreg', GPRegression),\n",
    "\t\t\t  ('bayes_ridge', BayesianRidge()),\n",
    "\t\t\t  ('Gboost', GradientBoostingRegressor()),\n",
    "\t\t\t  ('support_vec_reg', SVR())\n",
    "\t\t\t ]\n",
    "\n",
    "# CREATE CLASSIFICATION MODELS\n",
    "class_models = [('gpclass', GPClassification),\n",
    "\t\t\t\t('ridge_class', RidgeClassifier()),\n",
    "\t\t\t\t('gbclass', GradientBoostingClassifier()),\n",
    "\t\t\t\t('support_vec_class', SVC()),\n",
    "\t\t\t\t('naivebayes', BernoulliNB())\n",
    "\t\t \t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE INPUTS LIST\n",
    "def get_array_percentiles(array):\n",
    "\t\tdef percentile(x, array):\n",
    "\t\t\treturn 100*np.mean(array <= x)\n",
    "\n",
    "\t\treturn np.array(map(lambda x: percentile(x, array), array))\n",
    "\n",
    "def get_percentiles(df):\n",
    "\tif isinstance(df, pd.DataFrame):\n",
    "\t\tnew_df = df.copy()\n",
    "\t\treturn new_df.apply(lambda x: get_array_percentiles(x), axis = 0)\n",
    "\telif isinstance(df, np.ndarray):\n",
    "\t\treturn np.apply_along_axis(get_percentiles, 0, a)\n",
    "\telse:\n",
    "\t\tprint \"TYPE ERROR; PLEASE INPUT pd.DataFrame OR np.ndarray\"\n",
    "\t\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"skills_2009.csv\")\n",
    "X_skills, X_task, X_context = X, X, X\n",
    "# X_skills = pd.read_csv(\"X_skills.csv\")\n",
    "# X_task = pd.read_csv(\"X_task.csv\")\n",
    "# X_context = pd.read_csv(\"X_context.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"automation_targets.csv\")\n",
    "Y.columns = [\"O*NET-SOC Code\", \"auto_15\", \"auto_9\", \"delta\", \"auto_delta_pct\", \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"skills_2009.csv\")\n",
    "X_skills, X_task, X_context = X, X, X\n",
    "codes = pd.read_csv(\"codes_index.csv\")\n",
    "full_X = pd.concat((X_skills, codes), axis = 1)\n",
    "full_X = full_X.merge(Y, on = \"O*NET-SOC Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for dX in [full_X]:\n",
    "    pctiles = get_percentiles(dX)\n",
    "    d_list =  [('dx', dX), ('pctile', pctiles)]\n",
    "    for d in d_list:\n",
    "        prefix = d[0]\n",
    "        data = d[1]\n",
    "        inputs.append((prefix, data.iloc[:,:-6]))\n",
    "        inputs.append((prefix + '_greater_than', data[data.auto_delta_pct > 0].iloc[:,:-6]))\n",
    "        inputs.append((prefix + '_less_than', data[data.auto_delta_pct < 0].iloc[:,:-6]))\n",
    "# \t\tinputs.append(data[emp_delta_pct > 0])\n",
    "# \t\tinputs.append(data[emp_delta_pct < 0])\n",
    "\n",
    "# new_inputs = []\n",
    "# for inp in inputs:\n",
    "#     new_inputs.append(inp[0], inp[1].iloc[:,:-6])\n",
    "\n",
    "# inputs = new_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FINAL DATA\n",
    "y_out = full_X[['auto_9', 'auto_15', 'delta', 'auto_delta_pct']]\n",
    "codes = full_X[\"O*NET-SOC Code\"]\n",
    "\n",
    "full_X = full_X.drop(['O*NET-SOC Code', 'auto_9', 'auto_15', 'delta', 'auto_delta_pct', 'title'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# automation = pd.read_csv(\"y_automation.csv\")\n",
    "# computerisation = pd.read_csv(\"y_computerisation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE REG TARGETS\n",
    "y_before = ('before', y_out.auto_9)\n",
    "y_after = ('after', y_out.auto_15)\n",
    "y_delta = ('delta', y_out.delta)\n",
    "y_pct = ('delta_pct', y_out.auto_delta_pct)\n",
    "reg_targets = [y_before, y_after, y_delta, y_pct]\n",
    "\n",
    "new_reg_targets = []\n",
    "for name, series in reg_targets:\n",
    "    new_reg_targets.append((name, series))\n",
    "    new_name = name + '_pctile'\n",
    "    new_series = get_array_percentiles(series)\n",
    "    new_reg_targets.append((new_name, new_series))\n",
    "    \n",
    "reg_targets = new_reg_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE CLASS TARGETS\n",
    "class_targets = []\n",
    "pos_threshold_values = [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00]\n",
    "neg_threshold_values = map(lambda x: -x, pos_threshold_values)\n",
    "threshold_values = pos_threshold_values + neg_threshold_values\n",
    "\n",
    "for name, target in reg_targets:\n",
    "    for sd_threshold_value in threshold_values:\n",
    "        low_threshold = target > (np.mean(target) - sd_threshold_value*np.std(target))\n",
    "        new_name = str(sd_threshold_value)+\"_gt_\" + name\n",
    "        class_targets.append((new_name,low_threshold))\n",
    "\n",
    "# \tmean_threshold = target > np.mean(target)\n",
    "# \tnew_name = 'mean_gt_' + name\n",
    "# \tclass_targets.append((name, mean_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_inputs = inputs\n",
    "y_inputs_reg, y_inputs_class = reg_targets, class_targets\n",
    "models_reg, models_class = reg_models, class_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   2,   3,  15,  16,  24,  26,  29,  32,  39,\n",
       "            ...\n",
       "            719, 722, 727, 730, 736, 748, 749, 750, 752, 756],\n",
       "           dtype='int64', length=225)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_inputs[1][1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_inputs[0]\n",
    "y = y_inputs_reg[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_name, y_targ = y[0], y[1] > 0\n",
    "y = (y_name, y_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr_x, te_x, tr_y, te_y = train_test_split(X[1], y_targ)\n",
    "m = SVC(probability = True)\n",
    "m.fit(tr_x, tr_y)\n",
    "preds = m.predict_proba(te_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71000304,  0.28999696],\n",
       "       [ 0.71000631,  0.28999369],\n",
       "       [ 0.71000708,  0.28999292],\n",
       "       [ 0.71000471,  0.28999529],\n",
       "       [ 0.71000694,  0.28999306],\n",
       "       [ 0.71000643,  0.28999357],\n",
       "       [ 0.71000517,  0.28999483],\n",
       "       [ 0.71000517,  0.28999483],\n",
       "       [ 0.71000609,  0.28999391],\n",
       "       [ 0.71000438,  0.28999562],\n",
       "       [ 0.71000517,  0.28999483],\n",
       "       [ 0.71000514,  0.28999486],\n",
       "       [ 0.71000605,  0.28999395],\n",
       "       [ 0.7100016 ,  0.2899984 ],\n",
       "       [ 0.71000665,  0.28999335],\n",
       "       [ 0.71000234,  0.28999766],\n",
       "       [ 0.71000521,  0.28999479],\n",
       "       [ 0.71000702,  0.28999298],\n",
       "       [ 0.71000432,  0.28999568],\n",
       "       [ 0.71000318,  0.28999682],\n",
       "       [ 0.71000598,  0.28999402],\n",
       "       [ 0.71000561,  0.28999439],\n",
       "       [ 0.71000616,  0.28999384],\n",
       "       [ 0.71000653,  0.28999347],\n",
       "       [ 0.71000644,  0.28999356],\n",
       "       [ 0.71000641,  0.28999359],\n",
       "       [ 0.71000507,  0.28999493],\n",
       "       [ 0.71000593,  0.28999407],\n",
       "       [ 0.71000362,  0.28999638],\n",
       "       [ 0.71000503,  0.28999497],\n",
       "       [ 0.71000536,  0.28999464],\n",
       "       [ 0.71000646,  0.28999354],\n",
       "       [ 0.71000664,  0.28999336],\n",
       "       [ 0.71000578,  0.28999422],\n",
       "       [ 0.71000379,  0.28999621],\n",
       "       [ 0.71000565,  0.28999435],\n",
       "       [ 0.7100025 ,  0.2899975 ],\n",
       "       [ 0.71000636,  0.28999364],\n",
       "       [ 0.71000518,  0.28999482],\n",
       "       [ 0.71000505,  0.28999495],\n",
       "       [ 0.71000461,  0.28999539],\n",
       "       [ 0.71000579,  0.28999421],\n",
       "       [ 0.71000657,  0.28999343],\n",
       "       [ 0.71000603,  0.28999397],\n",
       "       [ 0.71000604,  0.28999396],\n",
       "       [ 0.7100069 ,  0.2899931 ],\n",
       "       [ 0.71000095,  0.28999905],\n",
       "       [ 0.71000713,  0.28999287],\n",
       "       [ 0.7100062 ,  0.2899938 ],\n",
       "       [ 0.7100068 ,  0.2899932 ],\n",
       "       [ 0.71000605,  0.28999395],\n",
       "       [ 0.71000468,  0.28999532],\n",
       "       [ 0.71000638,  0.28999362],\n",
       "       [ 0.71000693,  0.28999307],\n",
       "       [ 0.71000423,  0.28999577],\n",
       "       [ 0.71000278,  0.28999722],\n",
       "       [ 0.7100036 ,  0.2899964 ],\n",
       "       [ 0.710007  ,  0.289993  ],\n",
       "       [ 0.71000781,  0.28999219],\n",
       "       [ 0.71000639,  0.28999361],\n",
       "       [ 0.71000641,  0.28999359],\n",
       "       [ 0.71000595,  0.28999405],\n",
       "       [ 0.71000419,  0.28999581],\n",
       "       [ 0.71000454,  0.28999546],\n",
       "       [ 0.71000634,  0.28999366],\n",
       "       [ 0.71000391,  0.28999609],\n",
       "       [ 0.71000644,  0.28999356],\n",
       "       [ 0.71000595,  0.28999405],\n",
       "       [ 0.71000843,  0.28999157],\n",
       "       [ 0.70999971,  0.29000029],\n",
       "       [ 0.71000548,  0.28999452],\n",
       "       [ 0.71000675,  0.28999325],\n",
       "       [ 0.71000619,  0.28999381],\n",
       "       [ 0.71000556,  0.28999444],\n",
       "       [ 0.71000508,  0.28999492],\n",
       "       [ 0.71000447,  0.28999553],\n",
       "       [ 0.71000534,  0.28999466],\n",
       "       [ 0.71000676,  0.28999324],\n",
       "       [ 0.7100036 ,  0.2899964 ],\n",
       "       [ 0.71000523,  0.28999477],\n",
       "       [ 0.71000316,  0.28999684],\n",
       "       [ 0.71000528,  0.28999472],\n",
       "       [ 0.71000108,  0.28999892],\n",
       "       [ 0.71000535,  0.28999465],\n",
       "       [ 0.71000603,  0.28999397],\n",
       "       [ 0.71000227,  0.28999773],\n",
       "       [ 0.71000483,  0.28999517],\n",
       "       [ 0.71000219,  0.28999781],\n",
       "       [ 0.71000499,  0.28999501],\n",
       "       [ 0.71000588,  0.28999412],\n",
       "       [ 0.71000564,  0.28999436],\n",
       "       [ 0.71000508,  0.28999492],\n",
       "       [ 0.7100063 ,  0.2899937 ],\n",
       "       [ 0.71000324,  0.28999676],\n",
       "       [ 0.71000522,  0.28999478],\n",
       "       [ 0.71000554,  0.28999446],\n",
       "       [ 0.71000653,  0.28999347],\n",
       "       [ 0.71000529,  0.28999471],\n",
       "       [ 0.7100048 ,  0.2899952 ],\n",
       "       [ 0.71000633,  0.28999367],\n",
       "       [ 0.71000628,  0.28999372],\n",
       "       [ 0.7100063 ,  0.2899937 ],\n",
       "       [ 0.71000642,  0.28999358],\n",
       "       [ 0.71000642,  0.28999358],\n",
       "       [ 0.71000618,  0.28999382],\n",
       "       [ 0.71000413,  0.28999587],\n",
       "       [ 0.71000739,  0.28999261],\n",
       "       [ 0.71000611,  0.28999389],\n",
       "       [ 0.71000579,  0.28999421],\n",
       "       [ 0.7100047 ,  0.2899953 ],\n",
       "       [ 0.71000401,  0.28999599],\n",
       "       [ 0.71000358,  0.28999642],\n",
       "       [ 0.71000744,  0.28999256],\n",
       "       [ 0.71000525,  0.28999475],\n",
       "       [ 0.71000479,  0.28999521],\n",
       "       [ 0.71000378,  0.28999622],\n",
       "       [ 0.71000826,  0.28999174],\n",
       "       [ 0.71000681,  0.28999319],\n",
       "       [ 0.71000778,  0.28999222],\n",
       "       [ 0.71000536,  0.28999464],\n",
       "       [ 0.71000549,  0.28999451],\n",
       "       [ 0.7100057 ,  0.2899943 ],\n",
       "       [ 0.71000769,  0.28999231],\n",
       "       [ 0.71000565,  0.28999435],\n",
       "       [ 0.7100061 ,  0.2899939 ],\n",
       "       [ 0.71000399,  0.28999601],\n",
       "       [ 0.71000462,  0.28999538],\n",
       "       [ 0.71000697,  0.28999303],\n",
       "       [ 0.71000658,  0.28999342],\n",
       "       [ 0.71000578,  0.28999422],\n",
       "       [ 0.71000716,  0.28999284],\n",
       "       [ 0.71000606,  0.28999394],\n",
       "       [ 0.71000642,  0.28999358],\n",
       "       [ 0.71000522,  0.28999478],\n",
       "       [ 0.71000536,  0.28999464],\n",
       "       [ 0.71000594,  0.28999406],\n",
       "       [ 0.71000772,  0.28999228],\n",
       "       [ 0.71000151,  0.28999849],\n",
       "       [ 0.71000568,  0.28999432],\n",
       "       [ 0.71000723,  0.28999277],\n",
       "       [ 0.71000399,  0.28999601],\n",
       "       [ 0.71000774,  0.28999226],\n",
       "       [ 0.71000591,  0.28999409],\n",
       "       [ 0.71000328,  0.28999672],\n",
       "       [ 0.71000789,  0.28999211],\n",
       "       [ 0.71000714,  0.28999286],\n",
       "       [ 0.71000646,  0.28999354],\n",
       "       [ 0.71000702,  0.28999298],\n",
       "       [ 0.71000345,  0.28999655],\n",
       "       [ 0.71000646,  0.28999354],\n",
       "       [ 0.71000683,  0.28999317],\n",
       "       [ 0.71000654,  0.28999346],\n",
       "       [ 0.71000561,  0.28999439],\n",
       "       [ 0.71000447,  0.28999553],\n",
       "       [ 0.71000528,  0.28999472],\n",
       "       [ 0.71000346,  0.28999654],\n",
       "       [ 0.71000439,  0.28999561],\n",
       "       [ 0.71000374,  0.28999626],\n",
       "       [ 0.71000698,  0.28999302],\n",
       "       [ 0.71000685,  0.28999315],\n",
       "       [ 0.71000833,  0.28999167],\n",
       "       [ 0.7100046 ,  0.2899954 ],\n",
       "       [ 0.71000452,  0.28999548],\n",
       "       [ 0.71000453,  0.28999547],\n",
       "       [ 0.71000883,  0.28999117],\n",
       "       [ 0.71000294,  0.28999706],\n",
       "       [ 0.71000577,  0.28999423],\n",
       "       [ 0.71000657,  0.28999343],\n",
       "       [ 0.71000455,  0.28999545],\n",
       "       [ 0.71000162,  0.28999838],\n",
       "       [ 0.71000603,  0.28999397],\n",
       "       [ 0.71000309,  0.28999691],\n",
       "       [ 0.71000588,  0.28999412],\n",
       "       [ 0.71000572,  0.28999428],\n",
       "       [ 0.7100088 ,  0.2899912 ],\n",
       "       [ 0.71000504,  0.28999496],\n",
       "       [ 0.71000635,  0.28999365],\n",
       "       [ 0.71000417,  0.28999583],\n",
       "       [ 0.7100057 ,  0.2899943 ],\n",
       "       [ 0.71000681,  0.28999319],\n",
       "       [ 0.7100068 ,  0.2899932 ],\n",
       "       [ 0.71000382,  0.28999618],\n",
       "       [ 0.710006  ,  0.289994  ],\n",
       "       [ 0.71000858,  0.28999142],\n",
       "       [ 0.71000646,  0.28999354],\n",
       "       [ 0.71000527,  0.28999473],\n",
       "       [ 0.71000526,  0.28999474],\n",
       "       [ 0.71000677,  0.28999323],\n",
       "       [ 0.71000638,  0.28999362],\n",
       "       [ 0.71000335,  0.28999665]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-c03cd30511aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'SVC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-09549c4ee312>\u001b[0m in \u001b[0;36mscore_model\u001b[0;34m(y_pred, y_test, X_inputs, models, score_type)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0ms_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0ms_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_TP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_TP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_FP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0ms_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_TP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_TP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_FN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0ms_specificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_TN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_TN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_FP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "score_model(preds, te_y, X, ('SVC', m), 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### aggregate models as list of tuples [(name, val), (name, val)]\n",
    "# loop\n",
    "\n",
    "def run_loop(X_inputs, y_inputs_reg = None, y_inputs_class = None, models_reg = None, models_class = None):\n",
    "    ## returns all models in comparison, as dict\n",
    "    tree = lambda: defaultdict(tree)\n",
    "    evals = tree()\n",
    "    \n",
    "    # begin loop over inputs\n",
    "    for X_inp in X_inputs: #FOR ALL INPUTS\n",
    "        X_name, X = X_inputs[0], X_inputs[1]\n",
    "        \n",
    "        # check if null pred_type\n",
    "        if y_inputs_reg and not y_inputs_class:\n",
    "            pred_type = 'regression'\n",
    "        \n",
    "        elif y_inputs_class and not y_inputs_reg:\n",
    "            pred_type = 'classification'\n",
    "        \n",
    "        elif not(y_inputs_reg or y_inputs_class):\n",
    "            raise \"Input a target variable!\"\n",
    "        \n",
    "        else: # both are fulfilled; perform classification & regression\n",
    "            new_dict = evals.copy()\n",
    "            for pred_type in ['regression', 'classification']:\n",
    "                if pred_type == 'regression':\n",
    "                    y_inps = y_inputs_reg\n",
    "                    mods = models_reg\n",
    "                elif pred_type == 'classification':\n",
    "                    y_inputs = y_inputs_class\n",
    "                    mods = models_class\n",
    "                else:\n",
    "                    return \"SOMETHING WRONG!\"\n",
    "                new_dict.update(run_model())\n",
    "                evals = new_dict\n",
    "        \n",
    "        evals = run_model()\n",
    "                \n",
    "        def run_model(pred_type):\n",
    "            model_evals = tree()\n",
    "        \n",
    "            # do inference over all targets\n",
    "\n",
    "            for y_inp in y_inps:\n",
    "                # format outcome data\n",
    "                y_name, y = y_inp[0], y_inp[1]\n",
    "                if y.ndim == 1:\n",
    "                    y = y[:, np.newaxis]\n",
    "\n",
    "                #format feature matrix data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "                data = [X_train, X_test, y_train, y_test]\n",
    "                new_data = []\n",
    "                # check that all data is np.ndarry\n",
    "                for d in data:\n",
    "                    if not isinstance(data, np.ndarray):\n",
    "                        new_data.append(np.array(data))\n",
    "                    else:\n",
    "                        new_data.append(data)\n",
    "                X_train, X_test, y_train, y_test = new_data\n",
    "\n",
    "                #loop over models\n",
    "                for mod in mods:\n",
    "                    model_name, model = models[0], models[1]\n",
    "                    try:\n",
    "                        model.fit(X_train, y_train)\n",
    "                    except AttributeError:\n",
    "                        model = model(X_train, y_train) # THESE ARE GPs!\n",
    "                        model.optimize()\n",
    "                        model.optimize_restarts(20)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    score = score_model(y_pred, y_test, X_inp, mod, score_type = pred_type) # CREATE TYPES\n",
    "                    model_evals[model_name] = score\n",
    "                return model_evals\n",
    "\n",
    "        return evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(y_pred, y_test, y_name, X_inputs, models, score_type):\n",
    "    score = {}\n",
    "    X_name, X = X_inputs[0], X_inputs[1]\n",
    "    model_name, model = models[0], models[1]\n",
    "    \n",
    "    score['Model name'] = model_name\n",
    "    score['Model'] = model\n",
    "    score['X_name'] = X_name\n",
    "    score['y_name'] = y_name\n",
    "    score['y_pred'] = y_pred\n",
    "    score['y_test'] = y_test\n",
    "\n",
    "    if score_type == \"classification\":\n",
    "        accuracy = -1\n",
    "        precision = None\n",
    "        recall = None\n",
    "        specificity = None\n",
    "        f1 = None\n",
    "        ideal_cutoff = None\n",
    "\n",
    "        chart_storage = np.array([None, None, None])\n",
    "        for cutoff in np.arange(0, 1.001, 0.001):\n",
    "            y_pred = y_pred > cutoff\n",
    "            num_TP = float(np.sum((y_pred == 1) & (y_test == 1)))\n",
    "            num_FP = float(np.sum((y_pred == 1) & (y_test == 0)))\n",
    "            num_TN = float(np.sum((y_pred == 0) & (y_test == 0)))\n",
    "            num_FN = float(np.sum((y_pred == 0) & (y_test == 1)))\n",
    "\n",
    "            s_accuracy = np.mean(y_pred == y_test)\n",
    "            s_precision = num_TP / (num_TP + num_FP)\n",
    "            s_recall = num_TP / (num_TP + num_FN)\n",
    "            s_specificity = num_TN / (num_TN + num_FP)\n",
    "            s_f1 = (precision * recall) / (precision + recall)\n",
    "\n",
    "            chart_storage.append([cutoff, s_recall, s_specificity])\n",
    "\n",
    "            if s_accuracy > accuracy:\n",
    "                ideal_cutoff = cutoff\n",
    "                precision = s_precision\n",
    "                recall = s_recall\n",
    "                specificity = s_specificity \n",
    "                f1 = s_f1\n",
    "                ideal_cutoff = s_ideal_cutoff\n",
    "\n",
    "        def plot_chart(chart_storage):\n",
    "            cutoffs = chart_storage[:,0]\n",
    "            sensitivity = chart_storage[:,1]\n",
    "            specificity = chart_storage[:,2]\n",
    "            sns.plt.plot(sensitivity, specificity)\n",
    "            sns.plt.close()\n",
    "\n",
    "        eval_text = \"\"\"\n",
    "        Model \t\t| \t{}\t\t|\n",
    "        X name\t\t|\t{}\t\t|\n",
    "        Accuracy\t|\t{}\t\t|\n",
    "        Precision  \t|\t{}\t\t|\n",
    "        Recall \t\t|\t{}\t\t|\n",
    "        Specificity |\t{}\t\t|\n",
    "        F1\t\t\t|\t{}\t\t|\n",
    "        \"\"\".format(model_name,\n",
    "                   X_name,\n",
    "                   accuracy,\n",
    "                   precision,\n",
    "                   recalll,\n",
    "                   specificity,\n",
    "                   f1)\n",
    "        score['Accuracy'] = accuracy\n",
    "        score['Precision'] = precision\n",
    "        score['Recall'] = recall\n",
    "        score['Specificity'] = specificity\n",
    "        score['F1'] = F1\n",
    "        score['AUC_data'] = chart_storage\n",
    "        score['chart'] = plot_chart # when called, call on plot_chart( score['AUC_data'])\n",
    "\n",
    "        print eval_text\n",
    "        return score\n",
    "\n",
    "    elif score_type == 'regression':\n",
    "        errors = y_test - y_pred\n",
    "        se = float(np.std(errors)) / np.sqrt(len(errors))\n",
    "        try:\n",
    "            likelihood = model.likelihood\n",
    "        except:\n",
    "            likelihood = 'N/A'\n",
    "\n",
    "        eval_text = \"\"\"\n",
    "        Model name  |     {}\n",
    "        X name      |     {}\n",
    "        Mean Y      |     {}\n",
    "        Mean Y_hat  |     {}\n",
    "        Mean error  |     {}\n",
    "        SE          |     {}\n",
    "        Likelihood  |     ##\n",
    "        \"\"\".format(model_name,\n",
    "                   X_name,\n",
    "                   np.mean(y_test),\n",
    "                   np.mean(y_pred),\n",
    "                   np.mean(errors),\n",
    "                   se\n",
    "#                    likelihood\n",
    "                   )\n",
    "        score['likelihood'] = likelihood\n",
    "        score['Standard Error'] = se\n",
    "        score['mean y'] = np.mean(y_test)\n",
    "        score['mean y_hat'] = np.mean(y_pred)\n",
    "        score['mean_error'] = np.mean(errors)\n",
    "        \n",
    "        ## plot pca\n",
    "\n",
    "        ## plot errors\n",
    "\n",
    "        print eval_text\n",
    "        return score\n",
    "    else:\n",
    "        return \"Please input a valid score_type {'regression', 'classification'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_ARD(model, feature_names):\n",
    "\t# uses ARD to find relevant features\n",
    "\tlength_scales = model.length_scales # np.ndarray\n",
    "\tfeatures = range(1, len(model.features) + 1)\n",
    "\timportances = 1./length_scales\n",
    "\tcutoff = 0.25 * min(importances) # note: arbitrary\n",
    "\timportant_features = features * (importances >= cutoff)\n",
    "\tif_indices = np.trim_zeros(important_features)\n",
    "\treturn zip(feature_names[if_indices], importances[if_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = list(t.columns[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = t[out], t.drop(out, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto = pd.read_csv('automation_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'O*NET-SOC Code', u'automation_15', u'automation_9', u'delta',\n",
       "       u'delta_pct', u'Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_table(\"../../databases/db09/Skills.txt\")\n",
    "X = X[X['Scale ID'] == 'LV']\n",
    "X = X.pivot_table(values = 'Data Value', index = 'O*NET-SOC Code', columns = 'Element Name')\n",
    "X = X.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'x'\n",
    "output_columns = auto\n",
    "subset_columns = 'delta_pct'\n",
    "y_before = 'automation_9'\n",
    "y_after = 'automation_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING X's\n",
      "TRANFORMING X's\n",
      "CREATING y's\n"
     ]
    }
   ],
   "source": [
    "inps = generate_inputs(name, X, output_columns, subset_columns, y_before, y_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_inputs(X_name, X_input, output_columns, subset_columns, y_before_name, y_after_name, job_codes = None):\n",
    "    \"\"\"\n",
    "    X_name: name of X_input\n",
    "    X_input: raw input with O*NET-SOC Code\n",
    "    output_columns: interest variable df, like automation, with O*NET-SOC Code\n",
    "    subset_columns: output columns you want to subset X on. Str or List\n",
    "    y_before: name of column containing before target\n",
    "    y_after: name of column containing after target\n",
    "    job_codes: necessary only if \n",
    "    \"\"\"\n",
    "    X = X_input.copy()\n",
    "    # first, format inputs\n",
    "    if job_codes and \"O*NET-SOC Code\" not in X_input.columns:\n",
    "        X = pd.concat((X_input, job_codes), axis = 1)\n",
    "\n",
    "    X = X.merge(output_columns, on = 'O*NET-SOC Code', how = 'inner')\n",
    "\n",
    "\n",
    "    # generate X subsets\n",
    "    print \"CREATING X's\"\n",
    "    if isinstance(subset_columns, str):\n",
    "        subset_columns = [subset_columns]\n",
    "\n",
    "    subset_inputs = []\n",
    "    subset_inputs.append(['full', X])\n",
    "    for subset in subset_columns:\n",
    "        Xss = X[subset]\n",
    "        s = subset\n",
    "        subset_inputs.append(['pos_change_' + s, X[Xss > 0]])\n",
    "        subset_inputs.append(['neg_change_' + s, X[Xss < 0]])\n",
    "        subset_inputs.append(['gt_mean_' + s, X[Xss > Xss.mean()]])\n",
    "        subset_inputs.append(['lt_mean_' + s, X[Xss < Xss.mean()]])\n",
    "\n",
    "    # generate transforms\n",
    "    print \"TRANFORMING X's\"\n",
    "    transformed_inputs = []\n",
    "    cols = list(output_columns.columns)\n",
    "    for subset_input in subset_inputs:\n",
    "        transformed_inputs.append(subset_input)\n",
    "        name, df = subset_input[0], subset_input[1]\n",
    "        retain = df[cols]\n",
    "        of_interest = df.drop(cols, axis = 1)\n",
    "\n",
    "        # percentile\n",
    "        pct_df = get_percentiles(of_interest)\n",
    "        pct_df = pd.concat((pct_df, retain), axis = 1)\n",
    "        pct_name = 'pile_' + name\n",
    "\n",
    "        # log change\n",
    "        log_df = np.log(of_interest)\n",
    "        log_df = pd.concat((log_df, retain), axis = 1)\n",
    "        log_name = 'log_' + name\n",
    "\n",
    "        transformed_inputs.append([pct_name, pct_df])\n",
    "        transformed_inputs.append([log_name, log_df])\n",
    "\n",
    "    final_inputs = []\n",
    "    \n",
    "    # generate y inputs\n",
    "    print \"CREATING y's\"\n",
    "    for X in transformed_inputs:\n",
    "        new_y_inputs = []\n",
    "        X_name = X[0]\n",
    "        y_before, y_after = X[1][y_before_name], X[1][y_after_name]\n",
    "        delta = y_after - y_before\n",
    "        pct_delta = (y_after.astype(float) - y_before.astype(float)) / y_before\n",
    "        pile_pct_delta = get_array_percentiles(pct_delta)\n",
    "        pctile_before = get_array_percentiles(y_before)\n",
    "        pctile_after = get_array_percentiles(y_after)\n",
    "\n",
    "        new_y_inputs.append(['before', y_before])\n",
    "        new_y_inputs.append(['after', y_after])\n",
    "        new_y_inputs.append(['pct_delta', pct_delta])\n",
    "        new_y_inputs.append(['pile_pct_delta', pile_pct_delta])\n",
    "        new_y_inputs.append(['pctile_before', pctile_before])\n",
    "        new_y_inputs.append(['pctile_after', pctile_after])\n",
    "\n",
    "        final_y_inputs = []\n",
    "        for name, y_input in new_y_inputs:\n",
    "            final_y_inputs.append([name, y_input])\n",
    "            final_y_inputs.append(['log_' + name, np.log(y_input)])\n",
    "\n",
    "        X_final = X[1].drop(cols, axis = 1)\n",
    "        for y_name, y_input_final in final_y_inputs:\n",
    "            final_inputs.append([X_name, X_final, y_name, y_input_final])\n",
    "\n",
    "    return final_inputs\n",
    "\n",
    "\n",
    "def create_class_inputs(input_list):\n",
    "    \"\"\"\n",
    "    Input list has to be structured as a list of lists, s.t. the inner list is constructed:\n",
    "\n",
    "                [X_name, X, y_name, y]\n",
    "\n",
    "    \"\"\"\n",
    "    class_list = []\n",
    "    for i in input_list:\n",
    "        X_name, X, y_name, y = i[0], i[1], i[2], i[3]\n",
    "\n",
    "        # gt/lt than mean\n",
    "        class_list.append([X_name, X, \"gt_mean_\" + y_name, y > np.mean(y)])\n",
    "        class_list.append([X_name, X, \"lt_mean_\" + y_name, y < np.mean(y)])\n",
    "\n",
    "        # gt/lt than 0\n",
    "        if min(y) < 0 and max(y) > 0:\n",
    "            class_list.append([X_name, X, \"gt_0_\" + y_name, y > 0])\n",
    "            class_list.append([X_name, X, \"lt_0_\" + y_name, y < 0])\n",
    "\n",
    "        # gt/lt Z std deviations from mean\n",
    "        devs = np.array([0.5, 1, 1.5, 2, 2.5, 3])\n",
    "        devs = np.hstack((devs, -devs))\n",
    "        std = np.std(y)\n",
    "        mean = np.mean(y)\n",
    "        for sd in devs:\n",
    "            new_y = y > (mean + sd*std)\n",
    "            name = str(std) + \"_gt_\" + y_name\n",
    "            class_list.append([X_name, X, name, new_y])\n",
    "\n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_class_inputs(input_list):\n",
    "    \"\"\"\n",
    "    Input list has to be structured as a list of lists, s.t. the inner list is constructed:\n",
    "\n",
    "                [X_name, X, y_name, y]\n",
    "\n",
    "    \"\"\"\n",
    "    class_list = []\n",
    "    for i in input_list:\n",
    "        X_name, X, y_name, y = i[0], i[1], i[2], i[3]\n",
    "\n",
    "        # gt/lt than mean\n",
    "        class_list.append([X_name, X, \"gt_mean_\" + y_name, y > np.mean(y)])\n",
    "        class_list.append([X_name, X, \"lt_mean_\" + y_name, y < np.mean(y)])\n",
    "\n",
    "        # gt/lt than 0\n",
    "        if min(y) < 0 and max(y) > 0:\n",
    "            class_list.append([X_name, X, \"gt_0_\" + y_name, y > 0])\n",
    "            class_list.append([X_name, X, \"lt_0_\" + y_name, y < 0])\n",
    "\n",
    "        # gt/lt Z std deviations from mean\n",
    "        devs = np.array([0.5, 1, 1.5, 2, 2.5, 3])\n",
    "        devs = np.hstack((devs, -devs))\n",
    "        std = np.std(y)\n",
    "        mean = np.mean(y)\n",
    "        for sd in devs:\n",
    "            new_y = y > (mean + sd*std)\n",
    "            name = str(std) + \"_gt_\" + y_name\n",
    "            class_list.append([X_name, X, name, new_y])\n",
    "\n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing loop code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_loop(loop_type = 'regression', reg_inputs = None, class_inputs = None, reg_models = None, class_models = None):\n",
    "    ## returns all models in comparison, as dict\n",
    "    scores = defaultdict(list)\n",
    "    \n",
    "    if loop_type == \"regression\":\n",
    "        inputs = reg_inputs\n",
    "        models = reg_models\n",
    "    else:\n",
    "        inputs = class_inputs\n",
    "        models = class_models\n",
    "\n",
    "    for inp in inputs:\n",
    "        X_name, X, y_name, y = inp\n",
    "\n",
    "        # clean data in Numpy format\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:,np.newaxis]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        for model in models:\n",
    "            model_name, mod = model\n",
    "            try:\n",
    "                if y_train.ndim > 1:\n",
    "                    new_y_train = y_train.flatten()\n",
    "                mod.fit(X_train, new_y_train)\n",
    "                y_pred = mod.predict(X_test)\n",
    "            except AttributeError:\n",
    "                mod = mod(X_train, y_train)\n",
    "                mod.optimize()\n",
    "                mod.optimize_restarts(1)\n",
    "                y_pred, y_pred_var = mod.predict(X_test)\n",
    "                \n",
    "            score = score_model(y_pred, y_test, y_name, (X_name, X), model, score_type = loop_type) # CREATE TYPES\n",
    "            scores[model_name].append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_inputs = inps[:2]\n",
    "first_models = [('GPREG',GPRegression),('SVM',SVR())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b, c, d = first_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_x, te_x, tr_y, te_y = train_test_split(np.array(b), np.array(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
