{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Logan/Google Drive/Oxford/DPhil/future_employment/data/helpers/skills\n"
     ]
    }
   ],
   "source": [
    "cd ../../../data/helpers/skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('skills_2009.csv')\n",
    "Y = pd.read_csv('automation_targets.csv')\n",
    "codes = pd.read_csv('codes_index.csv')\n",
    "y = pd.read_csv('automation_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## UNSOLVED\n",
    "# Using time series data â€“ multiple years\n",
    "\n",
    "## NOTES ABOUT GP MODELS\n",
    "# optimize hyperparameters\n",
    "# perform random restarts\n",
    "# allow for multiple kernels\n",
    "# optimize kernels\n",
    "# optimize variances\n",
    "\n",
    "## TO DO\n",
    "# percentile regression model evaluation\n",
    "\n",
    "# CREATE REGRESSION MODELS\n",
    "from GPy.models import GPRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from GPy.models import GPClassification\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_models = [GPRegression,\n",
    "\t\t\t  BayesianRidge(),\n",
    "\t\t\t  GradientBoostingRegressor(),\n",
    "\t\t\t  SVR()\n",
    "\t\t\t ]\n",
    "\n",
    "# CREATE CLASSIFICATION MODELS\n",
    "class_models = [GPClassification,\n",
    "\t\t\t\tRidgeClassifier(),\n",
    "\t\t\t\tGradientBoostingClassifier(),\n",
    "\t\t\t\tSVC(),\n",
    "\t\t\t\tBernoulliNB()\n",
    "\t\t \t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE INPUTS LIST\n",
    "def get_array_percentiles(array):\n",
    "\t\tdef percentile(x, array):\n",
    "\t\t\treturn 100*np.mean(array <= x)\n",
    "\n",
    "\t\treturn np.array(map(lambda x: percentile(x, array), array))\n",
    "\n",
    "def get_percentiles(df):\n",
    "\tif isinstance(df, pd.DataFrame):\n",
    "\t\tnew_df = df.copy()\n",
    "\t\treturn new_df.apply(lambda x: get_array_percentiles(x), axis = 0)\n",
    "\telif isinstance(df, np.ndarray):\n",
    "\t\treturn np.apply_along_axis(get_percentiles, 0, a)\n",
    "\telse:\n",
    "\t\tprint \"TYPE ERROR; PLEASE INPUT pd.DataFrame OR np.ndarray\"\n",
    "\t\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"skills_2009.csv\")\n",
    "X_skills, X_task, X_context = X, X, X\n",
    "# X_skills = pd.read_csv(\"X_skills.csv\")\n",
    "# X_task = pd.read_csv(\"X_task.csv\")\n",
    "# X_context = pd.read_csv(\"X_context.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"automation_targets.csv\")\n",
    "Y.columns = [\"O*NET-SOC Code\", \"auto_15\", \"auto_9\", \"delta\", \"auto_delta_pct\", \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv(\"codes_index.csv\")\n",
    "full_X = pd.concat((X_skills, codes), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_X = full_X.merge(Y, on = \"O*NET-SOC Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for dX in [full_X]:\n",
    "\tpctiles = get_percentiles(dX)\n",
    "\tfor data in [dX, pctiles]:\n",
    "\t\tinputs.append(data)\n",
    "\t\tinputs.append(data[data.auto_delta_pct > 0])\n",
    "\t\tinputs.append(data[data.auto_delta_pct < 0])\n",
    "# \t\tinputs.append(data[emp_delta_pct > 0])\n",
    "# \t\tinputs.append(data[emp_delta_pct < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "automation = pd.read_csv(\"y_automation.csv\")\n",
    "computerisation = pd.read_csv(\"y_computerisation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE TARGET MODELS\n",
    "reg_targets = []\n",
    "for y in [automation, computerisation]:\n",
    "\ty_1, y_0 = y.iloc[:,1], y.iloc[:,0]\n",
    "\tp_1, p_0 = get_array_percentiles(y_1), get_array_percentiles(y_0)\n",
    "\tdelta = y_1 - y_0\n",
    "\tpctile_delta = p_1 - p_0\n",
    "\treg_targets.append(('before', y.iloc[:,0]))\n",
    "\treg_targets.append(('after', y.iloc[:,1]))\n",
    "\treg_targets.append(('delta', delta))\n",
    "\treg_targets.append(('pctile_delta', pctile_delta))\n",
    "\treg_targets.append(('pct_delta', delta/float(y_0))\n",
    "\treg_targets.append(('pct_pctile_delta', pctile_delta/float(p_0)))\n",
    "\n",
    "# CREATE CLASS TARGETS\n",
    "class_targets = []\n",
    "for name, target in reg_targets:\n",
    "\t# pct change\n",
    "\t# absolute delta\n",
    "\tfor sd_threshold_value in [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00]:\n",
    "\t\tlow_threshold = target > (np.mean(target) - sd_threshold_value*np.std(target))\n",
    "\t\tnew_name = str(sd_threshold_value)+\"_gt_\" + name\n",
    "\t\tclass_targets.append((name,low_threshold))\n",
    "\t\n",
    "\tmean_threshold = target > np.mean(target)\n",
    "\tnew_name = 'mean_gt_' + name\n",
    "\tclass_targets.append((name, mean_threshold))\n",
    "\n",
    "\n",
    "#### aggregate models as list of tuples [(name, val), (name, val)]\n",
    "# loop\n",
    "\n",
    "def run_loop(X_inputs, y_inputs, models):\n",
    "\t## returns all models in comparison, as dict\n",
    "\tevals = defaultdict(defaultdict({}))\n",
    "\tfor X_inp in X_inputs:\n",
    "\t\tX_name, X = X_inputs[0], X_inputs[1]\n",
    "\t\tfor y_inp in y_inputs:\n",
    "\t\t\t# format data\n",
    "\t\t\ty_name, y = y_inputs[0], y_inputs[1]\n",
    "\t\t\tX_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\t\t\tdata = [X_train, X_test, y_train, y_test]\n",
    "\t\t\tnew_data = []\n",
    "\t\t\t# check that all data is np.ndarry\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\tif not isinstance(data, np.ndarray):\n",
    "\t\t\t\t\tnew_data.append(np.array(data))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnew_data.append(data)\n",
    "\t\t\tX_train, X_test, y_train, y_test = new_data\n",
    "\n",
    "\t\t\t#loop over models\n",
    "\t\t\tfor mod in models:\n",
    "\t\t\t\tmodel_name, model, model_type = models[0], models[1], models[2]\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmodel.fit(X_train, y_train)\n",
    "\t\t\t\texcept AttributeError:\n",
    "\t\t\t\t\tmodel = model(X_train, y_train)\n",
    "\t\t\t\ty_pred = model.predict(X_test)\n",
    "\t\t\t\tscore = score_model(y_pred, y_test, X_inp, mod)\n",
    "\t\t\t\tevals[y_name][model_name][X_name] = score\n",
    "\treturn evals\n",
    "\n",
    "def do_ARD(model, feature_names):\n",
    "\t# uses ARD to find relevant features\n",
    "\tlength_scales = model.length_scales # np.ndarray\n",
    "\tfeatures = range(1, len(model.features) + 1)\n",
    "\timportances = 1./length_scales\n",
    "\tcutoff = 0.25 * min(importances) # note: arbitrary\n",
    "\timportant_features = features * (importances >= cutoff)\n",
    "\tif_indices = np.trim_zeros(important_features)\n",
    "\treturn zip(feature_names[if_indices], importances[if_indices])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------#\n",
    "#--------------------------------------------------#\n",
    "#--------------------------------------------------#\n",
    "#--------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score_model(y_pred, y_test, model_inputs, model):\n",
    "\tscore = {}\n",
    "\tX_name, X = model_inputs[0], model_inputs[1]\n",
    "\tmodel_name, model, model_type = models[0], models[1], models[2]\n",
    "\n",
    "\tif model_type == \"classification\":\n",
    "\t\taccuracy = -1\n",
    "\t\tprecision = None\n",
    "\t\trecall = None\n",
    "\t\tspecificity = None\n",
    "\t\tf1 = None\n",
    "\t\tideal_cutoff = None\n",
    "\n",
    "\t\tchart_storage = np.array([None, None, None])\n",
    "\t\tfor cutoff in np.arange(0, 1.001, 0.001):\n",
    "\t\t\ty_pred = y_pred > cutoff\n",
    "\t\t\tnum_TP = float(np.sum((y_pred == 1) & (y_test == 1)))\n",
    "\t\t\tnum_FP = float(np.sum((y_pred == 1) & (y_test == 0)))\n",
    "\t\t\tnum_TN = float(np.sum((y_pred == 0) & (y_test == 0)))\n",
    "\t\t\tnum_FN = float(np.sum((y_pred == 0) & (y_test == 1)))\n",
    "\n",
    "\t\t\ts_accuracy = np.mean(y_pred == y_test)\n",
    "\t\t\ts_precision = num_TP / (num_TP + num_FP)\n",
    "\t\t\ts_recall = num_TP / (num_TP + num_FN)\n",
    "\t\t\ts_specificity = num_TN / (num_TN + num_FP)\n",
    "\t\t\ts_f1 = (precision * recall) / (precision + recall)\n",
    "\n",
    "\t\t\tchart_storage.append([cutoff, s_recall, s_specificity])\n",
    "\n",
    "\t\t\tif s_accuracy > accuracy:\n",
    "\t\t\t\tideal_cutoff = cutoff\n",
    "\t\t\t\tprecision = s_precision\n",
    "\t\t\t\trecall = s_recall\n",
    "\t\t\t\tspecificity = s_specificity \n",
    "\t\t\t\tf1 = s_f1\n",
    "\t\t\t\tideal_cutoff = s_ideal_cutoff\n",
    "\n",
    "\t\tdef plot_chart(chart_storage):\n",
    "\t\t\tcutoffs = chart_storage[:,0]\n",
    "\t\t\tsensitivity = chart_storage[:,1]\n",
    "\t\t\tspecificity = chart_storage[:,2]\n",
    "\t\t\tsns.plt.plot(sensitivity, specificity)\n",
    "\t\t\tsns.plt.close()\n",
    "\n",
    "\t\teval_text = \"\"\"\n",
    "\t\tModel \t\t| \t{}\t\t|\n",
    "\t\tX name\t\t|\t{}\t\t|\n",
    "\t\tAccuracy\t|\t{}\t\t|\n",
    "\t\tPrecision  \t|\t{}\t\t|\n",
    "\t\tRecall \t\t|\t{}\t\t|\n",
    "\t\tSpecificity |\t{}\t\t|\n",
    "\t\tF1\t\t\t|\t{}\t\t|\n",
    "\t\t\"\"\".format(model_name,\n",
    "\t\t\t\t   X_name,\n",
    "\t\t\t\t   accuracy,\n",
    "\t\t\t\t   precision,\n",
    "\t\t\t\t   recalll,\n",
    "\t\t\t\t   specificity,\n",
    "\t\t\t\t   f1)\n",
    "\t\tscore['Model name'] = model_name\n",
    "\t\tscore['Model'] = model\n",
    "\t\tscore['X_name'] = X_name\n",
    "\t\tscore['Accuracy'] = accuracy\n",
    "\t\tscore['Precision'] = precision\n",
    "\t\tscore['Recall'] = recall\n",
    "\t\tscore['Specificity'] = specificity\n",
    "\t\tscore['F1'] = F1\n",
    "\t\tscore['AUC_data'] = chart_storage\n",
    "\t\tscore['chart'] = plot_chart # when called, call on plot_chart( score['AUC_data'])\n",
    "\n",
    "\t\tprint eval_text\n",
    "\t\treturn score\n",
    "\n",
    "\telse:\n",
    "\t\terrors = y_test - y_pred\n",
    "\t\tse = float(np.std(errors)) / np.sqrt(len(errors))\n",
    "\n",
    "\t\teval_text = \"\"\"\n",
    "\t\tModel \t\t| \t{}\t\t|\n",
    "\t\tX name\t\t|\t{}\t\t|\n",
    "\t\tMean Y\t\t|\t{}\t\t|\n",
    "\t\tMean Y_hat\t|\t{}\t\t|\n",
    "\t\tMean error\t|\t{}\t\t|\n",
    "\t\tSE\t\t\t| \t{}\t\t|\n",
    "\t\tLikelihood\t|\t{}\t\t|\n",
    "\t\t\"\"\".format(model_name,\n",
    "\t\t\t\t   X_name,\n",
    "\t\t\t\t   np.mean(y_test),\n",
    "\t\t\t\t   np.mean(y_pred),\n",
    "\t\t\t\t   np.mean(errors),\n",
    "\t\t\t\t   se,\n",
    "\t\t\t\t   likelihood\n",
    "\t\t\t\t   )\n",
    "\n",
    "\t\t## plot pca\n",
    "\t\t\n",
    "\t\t## plot errors\n",
    "\n",
    "\t\tprint eval_text\n",
    "\t\treturn score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
