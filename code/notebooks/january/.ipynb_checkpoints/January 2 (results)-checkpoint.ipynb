{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "# export to csv\n",
    "# run\n",
    "# serialize results\n",
    "# format results to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPy\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT SCRIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE INPUTS LIST\n",
    "def get_array_percentiles(array):\n",
    "\t\tdef percentile(x, array):\n",
    "\t\t\treturn 100*np.mean(array <= x)\n",
    "\n",
    "\t\treturn np.array(map(lambda x: percentile(x, array), array))\n",
    "\n",
    "def get_percentiles(df):\n",
    "\tif isinstance(df, pd.DataFrame):\n",
    "\t\tnew_df = df.copy()\n",
    "\t\treturn new_df.apply(lambda x: get_array_percentiles(x), axis = 0)\n",
    "\telif isinstance(df, np.ndarray):\n",
    "\t\treturn np.apply_along_axis(get_percentiles, 0, a)\n",
    "\telse:\n",
    "\t\tprint \"TYPE ERROR; PLEASE INPUT pd.DataFrame OR np.ndarray\"\n",
    "\t\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_inputs(X_name, X_input, output_columns, subset_columns, y_before_name, y_after_name, job_codes = None):\n",
    "    \"\"\"\n",
    "    X_name: name of X_input\n",
    "    X_input: raw input with O*NET-SOC Code\n",
    "    output_columns: interest variable df, like automation, with O*NET-SOC Code\n",
    "    subset_columns: output columns you want to subset X on. Str or List\n",
    "    y_before: name of column containing before target\n",
    "    y_after: name of column containing after target\n",
    "    job_codes: necessary only if \n",
    "    \"\"\"\n",
    "    X = X_input.copy()\n",
    "    # first, format inputs\n",
    "    if job_codes and \"O*NET-SOC Code\" not in X_input.columns:\n",
    "        X = pd.concat((X_input, job_codes), axis = 1)\n",
    "\n",
    "    X = X.merge(output_columns, on = 'O*NET-SOC Code', how = 'inner')\n",
    "\n",
    "\n",
    "    # generate X subsets\n",
    "    print \"CREATING X's\"\n",
    "    if isinstance(subset_columns, str):\n",
    "        subset_columns = [subset_columns]\n",
    "\n",
    "    subset_inputs = []\n",
    "    subset_inputs.append(['full', X])\n",
    "    for subset in subset_columns:\n",
    "        Xss = X[subset]\n",
    "        s = subset\n",
    "        subset_inputs.append(['pos_change_' + s, X[Xss > 0]])\n",
    "        subset_inputs.append(['neg_change_' + s, X[Xss < 0]])\n",
    "        subset_inputs.append(['gt_mean_' + s, X[Xss > Xss.mean()]])\n",
    "        subset_inputs.append(['lt_mean_' + s, X[Xss < Xss.mean()]])\n",
    "\n",
    "    # generate transforms\n",
    "    print \"TRANFORMING X's\"\n",
    "    transformed_inputs = []\n",
    "    cols = list(output_columns.columns)\n",
    "    for subset_input in subset_inputs:\n",
    "        transformed_inputs.append(subset_input)\n",
    "        X_name, df = subset_input[0], subset_input[1]\n",
    "        retain = df[cols]\n",
    "        of_interest = df.drop(cols, axis = 1)\n",
    "\n",
    "        # percentile\n",
    "        pct_df = get_percentiles(of_interest)\n",
    "        pct_df = pd.concat((pct_df, retain), axis = 1)\n",
    "        pct_name = 'pile_' + X_name\n",
    "        transformed_inputs.append([pct_name, pct_df])\n",
    "\n",
    "\n",
    "        # log change\n",
    "        if isinstance(of_interest, np.ndarray):\n",
    "            minimum = np.min(of_interest)\n",
    "        else:\n",
    "            minimum = of_interest.values.min()\n",
    "        if minimum > 0:\n",
    "            log_df = np.log(of_interest)\n",
    "            log_df = pd.concat((log_df, retain), axis = 1)\n",
    "            log_name = 'log_' + X_name\n",
    "            transformed_inputs.append([log_name, log_df])\n",
    "\n",
    "    final_inputs = []\n",
    "    \n",
    "    # generate y inputs\n",
    "    print \"CREATING y's\"\n",
    "    for X in transformed_inputs:\n",
    "        new_y_inputs = []\n",
    "        X_name = X[0]\n",
    "        y_before, y_after = X[1][y_before_name], X[1][y_after_name]\n",
    "        delta = y_after - y_before\n",
    "        pct_delta = (y_after.astype(float) - y_before.astype(float)) / y_before\n",
    "        pile_pct_delta = get_array_percentiles(pct_delta)\n",
    "        pctile_before = get_array_percentiles(y_before)\n",
    "        pctile_after = get_array_percentiles(y_after)\n",
    "\n",
    "        new_y_inputs.append(['before', y_before])\n",
    "        new_y_inputs.append(['after', y_after])\n",
    "        new_y_inputs.append(['pct_delta', pct_delta])\n",
    "        new_y_inputs.append(['pile_pct_delta', pile_pct_delta])\n",
    "        new_y_inputs.append(['pctile_before', pctile_before])\n",
    "        new_y_inputs.append(['pctile_after', pctile_after])\n",
    "\n",
    "        final_y_inputs = []\n",
    "        for y_name, y_input in new_y_inputs:\n",
    "            final_y_inputs.append([y_name, y_input])\n",
    "            if min(y_input) > 0.0:\n",
    "                final_y_inputs.append(['log_' + X_name, np.log(y_input)])\n",
    "\n",
    "        X_final = X[1].drop(cols, axis = 1)\n",
    "        for y_name, y_input_final in final_y_inputs:\n",
    "            final_inputs.append([X_name, X_final, y_name, y_input_final])\n",
    "\n",
    "    return final_inputs\n",
    "\n",
    "\n",
    "def create_class_inputs(input_list):\n",
    "    \"\"\"\n",
    "    Input list has to be structured as a list of lists, s.t. the inner list is constructed:\n",
    "\n",
    "                [X_name, X, y_name, y]\n",
    "\n",
    "    \"\"\"\n",
    "    class_list = []\n",
    "    for i in input_list:\n",
    "        X_name, X, y_name, y = i[0], i[1], i[2], i[3]\n",
    "\n",
    "        # gt/lt than mean\n",
    "        class_list.append([X_name, X, \"gt_mean_\" + y_name, y > np.mean(y)])\n",
    "        class_list.append([X_name, X, \"lt_mean_\" + y_name, y < np.mean(y)])\n",
    "\n",
    "        # gt/lt than 0\n",
    "        if min(y) < 0 and max(y) > 0:\n",
    "            class_list.append([X_name, X, \"gt_0_\" + y_name, y > 0])\n",
    "            class_list.append([X_name, X, \"lt_0_\" + y_name, y < 0])\n",
    "\n",
    "        # gt/lt Z std deviations from mean\n",
    "        devs = np.array([0.5, 1, 1.5, 2, 2.5, 3])\n",
    "        devs = np.hstack((devs, -devs))\n",
    "        std = np.std(y)\n",
    "        mean = np.mean(y)\n",
    "        for sd in devs:\n",
    "            new_y = y > (mean + sd*std)\n",
    "            name = str(std) + \"_gt_\" + y_name\n",
    "            class_list.append([X_name, X, name, new_y])\n",
    "\n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(y_pred, y_test, y_name, X_inputs, models, score_type):\n",
    "    score = {}\n",
    "    X_name, X = X_inputs[0], X_inputs[1]\n",
    "    model_name, model = models[0], models[1]\n",
    "    \n",
    "    score['Model name'] = model_name\n",
    "    score['Model'] = model\n",
    "    score['X_name'] = X_name\n",
    "    score['y_name'] = y_name\n",
    "    score['y_pred'] = y_pred\n",
    "    score['y_test'] = y_test\n",
    "    \n",
    "    try:\n",
    "        likelihood = model.likelihood\n",
    "    except:\n",
    "        likelihood = 'N/A'\n",
    "\n",
    "    if score_type == \"classification\":\n",
    "        accuracy = -1\n",
    "        precision = None\n",
    "        recall = None\n",
    "        specificity = None\n",
    "        f1 = None\n",
    "        ideal_cutoff = None\n",
    "\n",
    "        chart_storage = np.array([None, None, None])\n",
    "        for cutoff in np.arange(0, 1.001, 0.001):\n",
    "            y_pred = y_pred > cutoff\n",
    "            num_TP = float(np.sum((y_pred == 1) & (y_test == 1)))\n",
    "            num_FP = float(np.sum((y_pred == 1) & (y_test == 0)))\n",
    "            num_TN = float(np.sum((y_pred == 0) & (y_test == 0)))\n",
    "            num_FN = float(np.sum((y_pred == 0) & (y_test == 1)))\n",
    "\n",
    "            s_accuracy = np.mean(y_pred == y_test)\n",
    "            s_precision = num_TP / (num_TP + num_FP)\n",
    "            s_recall = num_TP / (num_TP + num_FN)\n",
    "            s_specificity = num_TN / (num_TN + num_FP)\n",
    "            s_f1 = (precision * recall) / (precision + recall)\n",
    "\n",
    "            chart_storage.append([cutoff, s_recall, s_specificity])\n",
    "\n",
    "            if s_accuracy > accuracy:\n",
    "                ideal_cutoff = cutoff\n",
    "                precision = s_precision\n",
    "                recall = s_recall\n",
    "                specificity = s_specificity \n",
    "                f1 = s_f1\n",
    "                ideal_cutoff = s_ideal_cutoff\n",
    "\n",
    "        def plot_chart(chart_storage):\n",
    "            cutoffs = chart_storage[:,0]\n",
    "            sensitivity = chart_storage[:,1]\n",
    "            specificity = chart_storage[:,2]\n",
    "            sns.plt.plot(sensitivity, specificity)\n",
    "            sns.plt.close()\n",
    "\n",
    "        eval_text = \"\"\"\n",
    "        Model \t\t| \t{}\t\t|\n",
    "        X name\t\t|\t{}\t\t|\n",
    "        Accuracy\t|\t{}\t\t|\n",
    "        Precision  \t|\t{}\t\t|\n",
    "        Recall \t\t|\t{}\t\t|\n",
    "        Specificity |\t{}\t\t|\n",
    "        F1\t\t\t|\t{}\t\t|\n",
    "        Likelihood  |   {}      |\n",
    "        \"\"\".format(y_name,\n",
    "                   model_name,\n",
    "                   X_name,\n",
    "                   accuracy,\n",
    "                   precision,\n",
    "                   recalll,\n",
    "                   specificity,\n",
    "                   f1,\n",
    "                   likelihood)\n",
    "        score['Accuracy'] = accuracy\n",
    "        score['Precision'] = precision\n",
    "        score['Recall'] = recall\n",
    "        score['Specificity'] = specificity\n",
    "        score['F1'] = F1\n",
    "        score['AUC_data'] = chart_storage\n",
    "        score['chart'] = plot_chart # when called, call on plot_chart( score['AUC_data'])\n",
    "\n",
    "        print eval_text\n",
    "        return score\n",
    "\n",
    "    elif score_type == 'regression':\n",
    "        errors = y_test - y_pred\n",
    "        se = float(np.std(errors)) / np.sqrt(len(errors))\n",
    "\n",
    "        eval_text = \"\"\"\n",
    "        y name      |     {}\n",
    "        Model name  |     {}\n",
    "        X name      |     {}\n",
    "        Mean Y      |     {}\n",
    "        Mean Y_hat  |     {}\n",
    "        Mean error  |     {}\n",
    "        SE          |     {}\n",
    "        Likelihood  |     {}\n",
    "        \"\"\".format(y_name,\n",
    "                   model_name,\n",
    "                   X_name,\n",
    "                   np.mean(y_test),\n",
    "                   np.mean(y_pred),\n",
    "                   np.mean(errors),\n",
    "                   se,\n",
    "                   likelihood\n",
    "                   )\n",
    "        score['likelihood'] = likelihood\n",
    "        score['Standard Error'] = se\n",
    "        score['mean y'] = np.mean(y_test)\n",
    "        score['mean y_hat'] = np.mean(y_pred)\n",
    "        score['mean_error'] = np.mean(errors)\n",
    "        \n",
    "        ## plot pca\n",
    "        ## plot errors\n",
    "\n",
    "        print eval_text\n",
    "        return score\n",
    "    else:\n",
    "        return \"Please input a valid score_type {'regression', 'classification'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_loop(loop_type = 'regression', reg_inputs = None, class_inputs = None, reg_models = None, class_models = None):\n",
    "    ## returns all models in comparison, as dict\n",
    "    scores = defaultdict(list)\n",
    "    \n",
    "    if loop_type == \"regression\":\n",
    "        inputs = reg_inputs\n",
    "        models = reg_models\n",
    "    else:\n",
    "        inputs = class_inputs\n",
    "        models = class_models\n",
    "\n",
    "    for inp in inputs:\n",
    "        X_name, X, y_name, y = inp\n",
    "\n",
    "        # clean data in Numpy format\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y[:,np.newaxis]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        for model in models:\n",
    "            model_name, mod = model\n",
    "            try:\n",
    "                if y_train.ndim > 1:\n",
    "                    new_y_train = y_train.flatten()\n",
    "                mod.fit(X_train, new_y_train)\n",
    "                y_pred = mod.predict(X_test)\n",
    "            except AttributeError:\n",
    "                mod = mod(X_train, y_train)\n",
    "                mod.optimize()\n",
    "                mod.optimize_restarts(10)\n",
    "                y_pred, y_pred_var = mod.predict(X_test)\n",
    "                \n",
    "            score = score_model(y_pred, y_test, y_name, (X_name, X), model, score_type = loop_type) # CREATE TYPES\n",
    "            scores[model_name].append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../../../data/helpers/skills/skills_2009.csv\")\n",
    "y = pd.read_csv(\"../../../data/helpers/automation/delta_9_15.csv\")\n",
    "\n",
    "X_name = 'skills_2009'\n",
    "output_columns = y\n",
    "subset_columns = ['delta', 'delta_pct']\n",
    "y_before, y_after = 'automation_9', 'automation_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING X's\n",
      "TRANFORMING X's\n",
      "CREATING y's\n"
     ]
    }
   ],
   "source": [
    "inps = generate_inputs(X_name, X, output_columns, subset_columns, y_before, y_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_inps = [inps[i] for i in np.random.randint(0, len(inps) - 1, 5)]\n",
    "class_inps = create_class_inputs(filter(lambda x: x[2] == 'pct_delta', inps)[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: len(set(x[3])), class_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [('GP REG', GPy.models.GPRegression),\n",
    "          ('SVR', SVR()),\n",
    "          ('Lasso', Lasso())]\n",
    "\n",
    "class_models = [('GP CLASS', GPy.models.GPClassification),\n",
    "                ('SVC', SVC())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = final_inps[0][1], final_inps[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad value for Bernoulli observation (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-ff36367cdef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_inps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-56c0607efb4a>\u001b[0m in \u001b[0;36mrun_loop\u001b[0;34m(loop_type, reg_inputs, class_inputs, reg_models, class_models)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_restarts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Logan/anaconda/envs/dev/lib/python2.7/site-packages/GPy/core/parameterization/parameterized.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_highest_parent_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connect_fixes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"calling parameters changed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Logan/anaconda/envs/dev/lib/python2.7/site-packages/GPy/core/gp.pyc\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0myourself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0munexpected\u001b[0m \u001b[0mconsequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_marginal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dthetaL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Logan/anaconda/envs/dev/lib/python2.7/site-packages/GPy/inference/latent_function_inference/expectation_propagation.pyc\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, kern, X, likelihood, Y, mean_function, Y_metadata, Z)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#if we don't yet have the results of runnign EP, run EP and store the computed factors in self._ep_approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ep_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpectation_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m#if we've already run EP, just use the existing approximation stored in self._ep_approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Logan/anaconda/envs/dev/lib/python2.7/site-packages/GPy/inference/latent_function_inference/expectation_propagation.pyc\u001b[0m in \u001b[0;36mexpectation_propagation\u001b[0;34m(self, K, Y, likelihood, Y_metadata)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mv_cav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_tilde\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m#Marginal moments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mZ_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments_match_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_cav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_cav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, Y_metadata=None)#=(None if Y_metadata is None else Y_metadata[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;31m#Site parameters update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mdelta_tau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma2_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Logan/anaconda/envs/dev/lib/python2.7/site-packages/GPy/likelihoods/bernoulli.pyc\u001b[0m in \u001b[0;36mmoments_match_ep\u001b[0;34m(self, Y_i, tau_i, v_i)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad value for Bernoulli observation (0, 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp_link\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_i\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau_i\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtau_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad value for Bernoulli observation (0, 1)"
     ]
    }
   ],
   "source": [
    "results = run_loop(loop_type = 'classification', class_inputs = class_inps, class_models = class_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.488889\n",
       "2      0.267327\n",
       "3      0.009615\n",
       "15     0.076923\n",
       "16     0.095960\n",
       "24     0.113861\n",
       "26     0.118943\n",
       "29     0.020761\n",
       "32     0.557769\n",
       "39     0.206667\n",
       "51     0.240343\n",
       "54     0.181818\n",
       "55     0.036066\n",
       "56     0.165289\n",
       "57     0.049822\n",
       "59     0.593985\n",
       "63     0.042735\n",
       "64     0.090000\n",
       "65     0.039604\n",
       "69     0.345238\n",
       "72     0.276042\n",
       "74     0.489510\n",
       "75     0.024272\n",
       "77     0.019324\n",
       "81     0.083770\n",
       "82     0.604478\n",
       "83     0.023256\n",
       "85     0.360825\n",
       "86     0.061538\n",
       "90     0.127572\n",
       "         ...   \n",
       "629    0.059233\n",
       "649    0.172043\n",
       "669    0.006623\n",
       "672    0.082237\n",
       "674    0.093093\n",
       "678    0.155116\n",
       "681    0.385787\n",
       "685    0.093023\n",
       "690    0.105590\n",
       "692    0.067114\n",
       "698    0.149798\n",
       "702    0.078704\n",
       "703    0.061404\n",
       "705    0.087649\n",
       "708    0.212963\n",
       "710    0.291667\n",
       "713    0.135000\n",
       "714    0.022857\n",
       "715    0.273256\n",
       "717    0.025641\n",
       "719    0.087558\n",
       "722    0.180723\n",
       "727    0.453947\n",
       "730    0.133333\n",
       "736    0.040161\n",
       "748    0.464286\n",
       "749    0.203297\n",
       "750    0.223529\n",
       "752    0.572368\n",
       "756    0.051195\n",
       "dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_inps[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
